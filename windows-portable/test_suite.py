#!/usr/bin/env python3
"""
Oracle to BigQuery Migration Tool - Windows í¬í„°ë¸” ë²„ì „ ìë™í™” í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸

ì™„ì „í•œ í…ŒìŠ¤íŠ¸ ìë™í™”ë¥¼ ìœ„í•œ í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸
- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸: í•µì‹¬ DDL ìƒì„± ê¸°ëŠ¥
- í†µí•© í…ŒìŠ¤íŠ¸: ì „ì²´ CSV to DDL ë³€í™˜ í”Œë¡œìš°
- ì„±ëŠ¥ í…ŒìŠ¤íŠ¸: ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì²˜ë¦¬
"""

import os
import sys
import csv
import json
import shutil
import subprocess
import tempfile
import unittest
import time
from pathlib import Path
from typing import Dict, List, Any, Optional

class DDLGeneratorUnitTests(unittest.TestCase):
    """DDL ìƒì„± í•µì‹¬ ê¸°ëŠ¥ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸"""
    
    def setUp(self):
        """í…ŒìŠ¤íŠ¸ ì„¤ì •"""
        # í…ŒìŠ¤íŠ¸ìš© SimpleMigrationTool ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        sys.path.insert(0, str(Path(__file__).parent / "windows" / "src"))
        from oracle_to_bq_cli import SimpleMigrationTool
        self.tool = SimpleMigrationTool(config_file=None)  # ì„¤ì • íŒŒì¼ ì—†ì´ ì´ˆê¸°í™”
        self.tool.project_id = "test-project"
        # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì¬ì„¤ì •
        self.tool.preserve_string_length = False
    
    def test_oracle_type_conversion(self):
        """Oracle íƒ€ì… ë³€í™˜ í…ŒìŠ¤íŠ¸"""
        test_cases = [
            # (oracle_type, precision, scale, expected_bq_type)
            ('NUMBER', '10', '0', 'INT64'),
            ('NUMBER', '15', '2', 'NUMERIC'),
            ('NUMBER', '38', '9', 'NUMERIC'),
            ('NUMBER', '76', '38', 'BIGNUMERIC'),
            ('NUMBER', None, None, 'NUMERIC'),
            ('VARCHAR2', None, None, 'STRING'),
            ('CHAR', None, None, 'STRING'),
            ('DATE', None, None, 'DATETIME'),
            ('TIMESTAMP', None, None, 'DATETIME'),
            ('CLOB', None, None, 'STRING'),
            ('BLOB', None, None, 'BYTES'),
        ]
        
        for oracle_type, precision, scale, expected in test_cases:
            with self.subTest(oracle_type=oracle_type, precision=precision, scale=scale):
                result = self.tool.convert_oracle_type(oracle_type, precision, scale)
                self.assertEqual(result, expected, 
                               f"Oracle {oracle_type}({precision},{scale}) -> {result}, expected {expected}")
    
    def test_encoding_detection(self):
        """ì¸ì½”ë”© ê°ì§€ í…ŒìŠ¤íŠ¸"""
        # UTF-8 íŒŒì¼ ìƒì„±
        utf8_file = Path("test_utf8.csv")
        with open(utf8_file, 'w', encoding='utf-8') as f:
            f.write("TABLE_NAME,COLUMN_NAME\ní•œê¸€í…Œì´ë¸”,í•œê¸€ì»¬ëŸ¼\n")
        
        try:
            encoding = self.tool.detect_encoding(utf8_file)
            self.assertEqual(encoding, 'utf-8', "UTF-8 ì¸ì½”ë”© ê°ì§€ ì‹¤íŒ¨")
        finally:
            if utf8_file.exists():
                utf8_file.unlink()
    
    def test_primary_key_generation(self):
        """ê¸°ë³¸í‚¤ ì œì•½ì¡°ê±´ ìƒì„± í…ŒìŠ¤íŠ¸"""
        columns = [
            {'column_name': 'ID', 'data_type': 'NUMBER', 'data_precision': '10', 'data_scale': '0', 
             'nullable': 'N', 'is_primary_key': 'Y', 'column_comment': 'ê¸°ë³¸í‚¤'},
            {'column_name': 'NAME', 'data_type': 'VARCHAR2', 'data_precision': '', 'data_scale': '', 
             'nullable': 'Y', 'is_primary_key': 'N', 'column_comment': 'ì´ë¦„'}
        ]
        
        ddl = self.tool.create_table_ddl('TEST_SCHEMA', 'TEST_TABLE', columns)
        
        self.assertIn('PRIMARY KEY (ID) NOT ENFORCED', ddl, "ê¸°ë³¸í‚¤ ì œì•½ì¡°ê±´ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
        self.assertIn('CREATE', ddl, "DDL êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ")
    
    def test_composite_primary_key_generation(self):
        """ë³µí•© ê¸°ë³¸í‚¤ ì œì•½ì¡°ê±´ ìƒì„± í…ŒìŠ¤íŠ¸"""
        columns = [
            {'column_name': 'ORDER_ID', 'data_type': 'NUMBER', 'data_precision': '10', 'data_scale': '0', 
             'nullable': 'N', 'is_primary_key': 'Y', 'column_comment': 'ì£¼ë¬¸ ID'},
            {'column_name': 'ITEM_ID', 'data_type': 'NUMBER', 'data_precision': '10', 'data_scale': '0', 
             'nullable': 'N', 'is_primary_key': 'Y', 'column_comment': 'ìƒí’ˆ ID'},
            {'column_name': 'QUANTITY', 'data_type': 'NUMBER', 'data_precision': '5', 'data_scale': '0', 
             'nullable': 'N', 'is_primary_key': 'N', 'column_comment': 'ìˆ˜ëŸ‰'}
        ]
        
        ddl = self.tool.create_table_ddl('TEST_SCHEMA', 'ORDER_ITEMS', columns)
        
        self.assertIn('PRIMARY KEY (ORDER_ID, ITEM_ID) NOT ENFORCED', ddl, "ë³µí•© ê¸°ë³¸í‚¤ ì œì•½ì¡°ê±´ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
        self.assertIn('CREATE', ddl, "DDL êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ")
    
    def test_project_id_handling(self):
        """project_id ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        columns = [
            {'column_name': 'ID', 'data_type': 'NUMBER', 'data_precision': '10', 'data_scale': '0', 
             'nullable': 'N', 'is_primary_key': 'Y', 'column_comment': 'í…ŒìŠ¤íŠ¸ ID'}
        ]
        
        # project_idê°€ ìˆëŠ” ê²½ìš°
        self.tool.project_id = 'my-project'
        ddl_with_project = self.tool.create_table_ddl('TEST_SCHEMA', 'TEST_TABLE', columns)
        self.assertIn('`my-project.TEST_SCHEMA.TEST_TABLE`', ddl_with_project, 
                     "project_idê°€ ìˆì„ ë•Œ í”„ë¡œì íŠ¸.ë°ì´í„°ì…‹.í…Œì´ë¸” í˜•íƒœê°€ ì•„ë‹˜")
        
        # project_idê°€ ì—†ëŠ” ê²½ìš° (ë¹ˆ ë¬¸ìì—´)
        self.tool.project_id = ''
        ddl_without_project = self.tool.create_table_ddl('TEST_SCHEMA', 'TEST_TABLE', columns)
        self.assertIn('`TEST_SCHEMA.TEST_TABLE`', ddl_without_project, 
                     "project_idê°€ ì—†ì„ ë•Œ ë°ì´í„°ì…‹.í…Œì´ë¸” í˜•íƒœê°€ ì•„ë‹˜")
        self.assertNotIn('..', ddl_without_project, "ë¹ˆ project_idë¡œ ì¸í•œ ì˜ëª»ëœ í˜•íƒœ")
        
        # project_idê°€ Noneì¸ ê²½ìš°
        self.tool.project_id = None
        ddl_none_project = self.tool.create_table_ddl('TEST_SCHEMA', 'TEST_TABLE', columns)
        self.assertIn('`TEST_SCHEMA.TEST_TABLE`', ddl_none_project, 
                     "project_idê°€ Noneì¼ ë•Œ ë°ì´í„°ì…‹.í…Œì´ë¸” í˜•íƒœê°€ ì•„ë‹˜")
    
    def test_auto_config_loading(self):
        """ìë™ config.json ë¡œë”© í…ŒìŠ¤íŠ¸"""
        # config_file=Noneìœ¼ë¡œ ì´ˆê¸°í™”í•  ë•Œ ìë™ìœ¼ë¡œ ì‹¤í–‰íŒŒì¼ ê²½ë¡œì˜ config.jsonì„ ì°¾ëŠ”ì§€ í…ŒìŠ¤íŠ¸
        from oracle_to_bq_cli import SimpleMigrationTool
        
        # config_file=Noneìœ¼ë¡œ ì´ˆê¸°í™”
        tool_auto = SimpleMigrationTool(config_file=None)
        
        # ê¸°ë³¸ê°’ì´ ì•„ë‹Œ ë‹¤ë¥¸ ê°’ì´ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ì‹¤ì œ config.jsonì´ ë¡œë“œë˜ì—ˆë‹¤ë©´)
        # ì´ í…ŒìŠ¤íŠ¸ëŠ” ì‹¤ì œ config.json íŒŒì¼ì˜ ì¡´ì¬ ì—¬ë¶€ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ
        self.assertIsNotNone(tool_auto.project_id, "project_idê°€ Noneì´ë©´ ì•ˆë¨")
        self.assertIsNotNone(tool_auto.string_mode, "string_modeê°€ Noneì´ë©´ ì•ˆë¨")
    
    def test_merged_ddl_generation(self):
        """ë³‘í•© DDL ìƒì„± í…ŒìŠ¤íŠ¸"""
        tables = {
            'TEST_SCHEMA.TABLE1': {
                'schema_name': 'TEST_SCHEMA',
                'table_name': 'TABLE1',
                'columns': [
                    {'column_name': 'ID', 'data_type': 'NUMBER', 'data_precision': '10', 'data_scale': '0',
                     'nullable': 'N', 'is_primary_key': 'Y', 'column_comment': ''}
                ]
            },
            'TEST_SCHEMA.TABLE2': {
                'schema_name': 'TEST_SCHEMA', 
                'table_name': 'TABLE2',
                'columns': [
                    {'column_name': 'NAME', 'data_type': 'VARCHAR2', 'data_precision': '', 'data_scale': '',
                     'nullable': 'Y', 'is_primary_key': 'N', 'column_comment': ''}
                ]
            }
        }
        
        output_file = Path("test_merged.sql")
        try:
            self.tool.generate_merged_ddl(tables, output_file)
            
            self.assertTrue(output_file.exists(), "ë³‘í•© DDL íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
            
            with open(output_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            self.assertIn('-- Oracle to BigQuery DDL Migration', content, "í—¤ë”ê°€ ì—†ìŒ")
            self.assertIn('-- Total tables: 2', content, "í…Œì´ë¸” ìˆ˜ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ")
            self.assertIn('CREATE', content, "DDLì´ í¬í•¨ë˜ì§€ ì•ŠìŒ")
            
        finally:
            if output_file.exists():
                output_file.unlink()
            if output_file.exists():
                output_file.unlink()
    
    def test_backtick_detection(self):
        """ë°±í‹± í•„ìš”ì„± ê²€ì‚¬ í…ŒìŠ¤íŠ¸"""
        test_cases = [
            # (name, needs_backticks)
            ('normal_column', False),
            ('í•œê¸€ì»¬ëŸ¼', True),
            ('123column', True),
            ('column-name', True),
            ('SELECT', True),  # ì˜ˆì•½ì–´
            ('FROM', True),    # ì˜ˆì•½ì–´
            ('valid_name_123', False),
        ]
        
        for name, expected in test_cases:
            with self.subTest(name=name):
                result = self.tool.needs_backticks(name)
                self.assertEqual(result, expected, 
                               f"'{name}' backticks needed: {result}, expected {expected}")
    
    def test_identifier_formatting(self):
        """ì‹ë³„ì í¬ë§·íŒ… í…ŒìŠ¤íŠ¸"""
        test_cases = [
            ('normal_column', 'normal_column'),
            ('í•œê¸€ì»¬ëŸ¼', '`í•œê¸€ì»¬ëŸ¼`'),
            ('123column', '`123column`'),
            ('SELECT', '`SELECT`'),
        ]
        
        for input_name, expected in test_cases:
            with self.subTest(input_name=input_name):
                result = self.tool.format_identifier(input_name)
                self.assertEqual(result, expected, 
                               f"'{input_name}' formatted as '{result}', expected '{expected}'")
    
    def test_bigquery_type_with_precision(self):
        """BigQuery íƒ€ì… ì •ë°€ë„ í¬ë§·íŒ… í…ŒìŠ¤íŠ¸"""
        test_cases = [
            # (bq_type, oracle_type, precision, scale, char_length, expected)
            ('NUMERIC', 'NUMBER', '10', '2', None, 'NUMERIC(10, 2)'),
            ('NUMERIC', 'NUMBER', '15', None, None, 'NUMERIC(15)'),
            ('STRING', 'VARCHAR2', None, None, '100', 'STRING'),
            ('INT64', 'NUMBER', '10', '0', None, 'INT64'),
        ]
        
        for bq_type, oracle_type, precision, scale, char_length, expected in test_cases:
            with self.subTest(bq_type=bq_type):
                result = self.tool.format_bigquery_type_with_precision(
                    bq_type, oracle_type, precision, scale, char_length)
                self.assertEqual(result, expected, 
                               f"Type formatting: {result}, expected {expected}")
    
    def test_description_escaping(self):
        """ì„¤ëª… í…ìŠ¤íŠ¸ ì´ìŠ¤ì¼€ì´í”„ í…ŒìŠ¤íŠ¸"""
        test_cases = [
            ('Simple description', 'Simple description'),
            ('Description with "quotes"', 'Description with \\"quotes\\"'),
            ('Multi\nline\ndescription', 'Multi line description'),
            ('  Extra   spaces  ', 'Extra spaces'),
        ]
        
        for input_desc, expected in test_cases:
            with self.subTest(input_desc=input_desc):
                result = self.tool.escape_description(input_desc)
                self.assertEqual(result, expected, 
                               f"Description escaped: '{result}', expected '{expected}'")

    def test_create_or_replace_option(self):
        """CREATE OR REPLACE TABLE ì˜µì…˜ í…ŒìŠ¤íŠ¸"""
        columns = [
            {'column_name': 'ID', 'data_type': 'NUMBER', 'data_precision': '10', 'data_scale': '0', 
             'nullable': 'N', 'is_primary_key': 'Y', 'column_comment': 'í…ŒìŠ¤íŠ¸ ID'},
            {'column_name': 'NAME', 'data_type': 'VARCHAR2', 'data_precision': '', 'data_scale': '', 
             'nullable': 'Y', 'is_primary_key': 'N', 'column_comment': 'ì´ë¦„'}
        ]
        
        # create_or_replace = False (ê¸°ë³¸ê°’)
        self.tool.create_or_replace = False
        ddl_create = self.tool.create_table_ddl('TEST_SCHEMA', 'TEST_TABLE', columns)
        self.assertIn('CREATE TABLE', ddl_create, "CREATE TABLEì´ í¬í•¨ë˜ì–´ì•¼ í•¨")
        self.assertNotIn('CREATE OR REPLACE TABLE', ddl_create, "CREATE OR REPLACE TABLEì´ í¬í•¨ë˜ë©´ ì•ˆë¨")
        
        # create_or_replace = True
        self.tool.create_or_replace = True
        ddl_create_or_replace = self.tool.create_table_ddl('TEST_SCHEMA', 'TEST_TABLE', columns)
        self.assertIn('CREATE OR REPLACE TABLE', ddl_create_or_replace, "CREATE OR REPLACE TABLEì´ í¬í•¨ë˜ì–´ì•¼ í•¨")
        self.assertNotIn('CREATE TABLE `', ddl_create_or_replace.replace('CREATE OR REPLACE TABLE', ''), 
                        "ë‹¨ìˆœ CREATE TABLEì´ í¬í•¨ë˜ë©´ ì•ˆë¨")

    def test_numeric_precision_limits(self):
        """NUMERIC ì •ë°€ë„ ì œí•œ í…ŒìŠ¤íŠ¸ (BigQuery ì œí•œì‚¬í•­ ì¤€ìˆ˜)"""
        test_cases = [
            # (precision, scale, expected_type)
            ('10', '0', 'INT64'),           # ì‘ì€ ì •ìˆ˜ -> INT64
            ('18', '0', 'INT64'),           # INT64 ìµœëŒ€ ë²”ìœ„
            ('25', '0', 'NUMERIC(25, 0)'),  # NUMERIC ë²”ìœ„ ë‚´ ì •ìˆ˜
            ('29', '0', 'NUMERIC(29, 0)'),  # NUMERIC ìµœëŒ€ ì •ìˆ˜ ì •ë°€ë„
            ('38', '0', 'BIGNUMERIC(38, 0)'), # í° ì •ìˆ˜ -> BIGNUMERIC
            ('50', '0', 'BIGNUMERIC(50, 0)'), # ë§¤ìš° í° ì •ìˆ˜ -> BIGNUMERIC
            ('15', '2', 'NUMERIC(15, 2)'),  # ì¼ë°˜ì ì¸ ì†Œìˆ˜
            ('38', '9', 'NUMERIC(38, 9)'),  # NUMERIC ìµœëŒ€ ë²”ìœ„
            ('50', '10', 'BIGNUMERIC(50, 10)'), # BIGNUMERIC ë²”ìœ„
        ]
        
        for precision, scale, expected in test_cases:
            with self.subTest(precision=precision, scale=scale):
                # Oracle NUMBER íƒ€ì…ì„ BigQuery íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                bq_type = self.tool.convert_oracle_type('NUMBER', precision, scale)
                formatted_type = self.tool.format_bigquery_type_with_precision(
                    bq_type, 'NUMBER', precision, scale, None)
                
                self.assertEqual(formatted_type, expected, 
                               f"NUMBER({precision},{scale}) -> {formatted_type}, expected {expected}")
    
    def test_debug_mode_configuration(self):
        """ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì • í…ŒìŠ¤íŠ¸"""
        # ê¸°ë³¸ê°’ì€ False
        self.assertFalse(self.tool.debug_mode, "ê¸°ë³¸ ë””ë²„ê·¸ ëª¨ë“œëŠ” Falseì—¬ì•¼ í•¨")
        
        # ì„¤ì •ì„ í†µí•œ ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”
        self.tool.debug_mode = True
        self.assertTrue(self.tool.debug_mode, "ë””ë²„ê·¸ ëª¨ë“œê°€ Trueë¡œ ì„¤ì •ë˜ì–´ì•¼ í•¨")
        
        # ì„¤ì •ì„ í†µí•œ ë””ë²„ê·¸ ëª¨ë“œ ë¹„í™œì„±í™”
        self.tool.debug_mode = False
        self.assertFalse(self.tool.debug_mode, "ë””ë²„ê·¸ ëª¨ë“œê°€ Falseë¡œ ì„¤ì •ë˜ì–´ì•¼ í•¨")
    
    def test_case_sensitivity_preservation(self):
        """ëŒ€ì†Œë¬¸ì ìœ ì§€ í…ŒìŠ¤íŠ¸"""
        columns = [
            {'column_name': 'Customer_ID', 'data_type': 'NUMBER', 'data_precision': '10', 'data_scale': '0', 
             'nullable': 'N', 'is_primary_key': 'Y', 'column_comment': 'ê³ ê° ID'},
            {'column_name': 'Customer_Name', 'data_type': 'VARCHAR2', 'data_precision': '', 'data_scale': '', 
             'nullable': 'Y', 'is_primary_key': 'N', 'column_comment': 'ê³ ê° ì´ë¦„'}
        ]
        
        # ëŒ€ì†Œë¬¸ìê°€ ì„ì¸ ìŠ¤í‚¤ë§ˆëª…ê³¼ í…Œì´ë¸”ëª…ìœ¼ë¡œ DDL ìƒì„±
        ddl = self.tool.create_table_ddl('MyDataset', 'Customer_Info', columns)
        
        # ë°ì´í„°ì…‹ëª…ê³¼ í…Œì´ë¸”ëª…ì´ ì›ë³¸ ëŒ€ì†Œë¬¸ì ê·¸ëŒ€ë¡œ ìœ ì§€ë˜ëŠ”ì§€ í™•ì¸
        self.assertIn('MyDataset.Customer_Info', ddl, "ë°ì´í„°ì…‹ëª…ê³¼ í…Œì´ë¸”ëª…ì˜ ëŒ€ì†Œë¬¸ìê°€ ìœ ì§€ë˜ì–´ì•¼ í•¨")
        self.assertIn('Customer_ID', ddl, "ì»¬ëŸ¼ëª…ì˜ ëŒ€ì†Œë¬¸ìê°€ ìœ ì§€ë˜ì–´ì•¼ í•¨")
        self.assertIn('Customer_Name', ddl, "ì»¬ëŸ¼ëª…ì˜ ëŒ€ì†Œë¬¸ìê°€ ìœ ì§€ë˜ì–´ì•¼ í•¨")
        
        # ì†Œë¬¸ìë¡œ ë³€í™˜ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
        self.assertNotIn('mydataset.customer_info', ddl, "ë°ì´í„°ì…‹ëª…ê³¼ í…Œì´ë¸”ëª…ì´ ì†Œë¬¸ìë¡œ ë³€í™˜ë˜ë©´ ì•ˆë¨")
        self.assertNotIn('customer_id', ddl, "ì»¬ëŸ¼ëª…ì´ ì†Œë¬¸ìë¡œ ë³€í™˜ë˜ë©´ ì•ˆë¨")
    
    def test_primary_key_limit_16(self):
        """ê¸°ë³¸í‚¤ 16ê°œ ì œí•œ í…ŒìŠ¤íŠ¸"""
        # 18ê°œì˜ ê¸°ë³¸í‚¤ ì»¬ëŸ¼ ìƒì„±
        columns = []
        for i in range(1, 19):
            columns.append({
                'column_name': f'PK{i:02d}',
                'data_type': 'NUMBER',
                'data_precision': '10',
                'data_scale': '0',
                'nullable': 'N',
                'is_primary_key': 'Y',
                'column_comment': f'Primary Key {i}'
            })
        
        # DDL ìƒì„±
        ddl = self.tool.create_table_ddl('TestSchema', 'TestTable', columns)
        
        # PRIMARY KEY ì ˆì— 16ê°œë§Œ í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
        self.assertIn('PRIMARY KEY', ddl, "ê¸°ë³¸í‚¤ ì œì•½ì¡°ê±´ì´ ìƒì„±ë˜ì–´ì•¼ í•¨")
        self.assertIn('PK01', ddl, "ì²« ë²ˆì§¸ ê¸°ë³¸í‚¤ê°€ í¬í•¨ë˜ì–´ì•¼ í•¨")
        self.assertIn('PK16', ddl, "16ë²ˆì§¸ ê¸°ë³¸í‚¤ê°€ í¬í•¨ë˜ì–´ì•¼ í•¨")
        
        # PRIMARY KEY ì ˆì—ì„œ PK17, PK18ì´ ì œì™¸ë˜ì—ˆëŠ”ì§€ í™•ì¸
        pk_section = ddl[ddl.find('PRIMARY KEY'):ddl.find('NOT ENFORCED')]
        self.assertNotIn('PK17', pk_section, "17ë²ˆì§¸ ê¸°ë³¸í‚¤ëŠ” ì œì™¸ë˜ì–´ì•¼ í•¨")
        self.assertNotIn('PK18', pk_section, "18ë²ˆì§¸ ê¸°ë³¸í‚¤ëŠ” ì œì™¸ë˜ì–´ì•¼ í•¨")
    
    def test_drop_partition_table_before_create(self):
        """íŒŒí‹°ì…˜ í…Œì´ë¸” ìƒì„± ì „ DROP ì˜µì…˜ í…ŒìŠ¤íŠ¸"""
        columns = [
            {'column_name': 'ID', 'data_type': 'NUMBER', 'data_precision': '10', 'data_scale': '0',
             'nullable': 'N', 'is_primary_key': 'Y', 'column_comment': 'ID', 'partition_yn': 'N'},
            {'column_name': 'CreateDate', 'data_type': 'TIMESTAMP', 'data_precision': '', 'data_scale': '',
             'nullable': 'Y', 'is_primary_key': 'N', 'column_comment': 'Date', 'partition_yn': 'Y'}
        ]
        
        # ì˜µì…˜ ë¹„í™œì„±í™” ì‹œ DROP ë¬¸ì´ ì—†ì–´ì•¼ í•¨
        self.tool.drop_partition_table_before_create = False
        self.tool.enable_partitioning = True
        ddl_without_drop = self.tool.create_table_ddl('TestSchema', 'TestTable', columns)
        self.assertNotIn('DROP TABLE', ddl_without_drop, "ì˜µì…˜ ë¹„í™œì„±í™” ì‹œ DROP ë¬¸ì´ ì—†ì–´ì•¼ í•¨")
        
        # ì˜µì…˜ í™œì„±í™” ì‹œ DROP ë¬¸ì´ ìˆì–´ì•¼ í•¨
        self.tool.drop_partition_table_before_create = True
        self.tool.create_or_replace = True
        ddl_with_drop = self.tool.create_table_ddl('TestSchema', 'TestTable', columns)
        self.assertIn('DROP TABLE IF EXISTS', ddl_with_drop, "ì˜µì…˜ í™œì„±í™” ì‹œ DROP ë¬¸ì´ ìˆì–´ì•¼ í•¨")
        self.assertIn('CREATE OR REPLACE TABLE', ddl_with_drop, "CREATE OR REPLACEë„ í¬í•¨ë˜ì–´ì•¼ í•¨")
        
        # íŒŒí‹°ì…˜ì´ ì—†ëŠ” í…Œì´ë¸”ì€ DROP ë¬¸ì´ ì—†ì–´ì•¼ í•¨
        columns_no_partition = [
            {'column_name': 'ID', 'data_type': 'NUMBER', 'data_precision': '10', 'data_scale': '0',
             'nullable': 'N', 'is_primary_key': 'Y', 'column_comment': 'ID', 'partition_yn': 'N'}
        ]
        ddl_no_partition = self.tool.create_table_ddl('TestSchema', 'TestTable', columns_no_partition)
        self.assertNotIn('DROP TABLE', ddl_no_partition, "íŒŒí‹°ì…˜ì´ ì—†ëŠ” í…Œì´ë¸”ì€ DROP ë¬¸ì´ ì—†ì–´ì•¼ í•¨")
    
    def test_unsupported_partition_types(self):
        """ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒí‹°ì…˜ íƒ€ì… í…ŒìŠ¤íŠ¸"""
        self.tool.enable_partitioning = True
        
        # STRING íƒ€ì… (VARCHAR2) - íŒŒí‹°ì…˜ ì§€ì› ì•ˆ í•¨
        columns_string = [
            {'column_name': 'ID', 'data_type': 'NUMBER', 'data_precision': '10', 'data_scale': '0',
             'nullable': 'N', 'is_primary_key': 'Y', 'column_comment': 'ID', 'partition_yn': 'N'},
            {'column_name': 'Name', 'data_type': 'VARCHAR2', 'data_precision': '', 'data_scale': '',
             'nullable': 'Y', 'is_primary_key': 'N', 'column_comment': 'Name', 'partition_yn': 'Y'}
        ]
        ddl_string = self.tool.create_table_ddl('TestSchema', 'TestTable', columns_string)
        self.assertNotIn('PARTITION BY', ddl_string, "STRING íƒ€ì…ì€ íŒŒí‹°ì…˜ì„ ì§€ì›í•˜ì§€ ì•Šì•„ì•¼ í•¨")
        
        # INT64 íƒ€ì… (NUMBER) - RANGE íŒŒí‹°ì…˜ í•„ìš”í•˜ë¯€ë¡œ ìƒì„± ì•ˆ í•¨
        columns_number = [
            {'column_name': 'ID', 'data_type': 'NUMBER', 'data_precision': '10', 'data_scale': '0',
             'nullable': 'N', 'is_primary_key': 'Y', 'column_comment': 'ID', 'partition_yn': 'Y'}
        ]
        ddl_number = self.tool.create_table_ddl('TestSchema', 'TestTable', columns_number)
        self.assertNotIn('PARTITION BY', ddl_number, "INT64 íƒ€ì…ì€ RANGE íŒŒí‹°ì…˜ ì„¤ì •ì´ í•„ìš”í•˜ì—¬ ìƒì„±í•˜ì§€ ì•Šì•„ì•¼ í•¨")
        
        # TIMESTAMP íƒ€ì… - íŒŒí‹°ì…˜ ì§€ì›í•¨
        columns_timestamp = [
            {'column_name': 'ID', 'data_type': 'NUMBER', 'data_precision': '10', 'data_scale': '0',
             'nullable': 'N', 'is_primary_key': 'Y', 'column_comment': 'ID', 'partition_yn': 'N'},
            {'column_name': 'CreateDate', 'data_type': 'TIMESTAMP', 'data_precision': '', 'data_scale': '',
             'nullable': 'Y', 'is_primary_key': 'N', 'column_comment': 'Date', 'partition_yn': 'Y'}
        ]
        ddl_timestamp = self.tool.create_table_ddl('TestSchema', 'TestTable', columns_timestamp)
        self.assertIn('PARTITION BY DATETIME_TRUNC(CreateDate, DAY)', ddl_timestamp, "TIMESTAMP íƒ€ì…ì€ DATETIMEìœ¼ë¡œ ë³€í™˜ë˜ì–´ DATETIME_TRUNC íŒŒí‹°ì…˜ì„ ì§€ì›í•´ì•¼ í•¨")


class WindowsPortableTestSuite:
    """Windows í¬í„°ë¸” ë²„ì „ í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸"""
    
    def __init__(self):
        self.root_dir = Path(__file__).parent
        self.windows_dir = self.root_dir / "windows"
        self.test_results = []
        
    def log_test(self, test_name: str, success: bool, message: str = ""):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¡œê¹…"""
        status = "âœ… PASS" if success else "âŒ FAIL"
        result = {
            "test": test_name,
            "success": success,
            "message": message
        }
        self.test_results.append(result)
        print(f"{status} {test_name}: {message}")
        
    def test_build_integrity(self) -> bool:
        """ë¹Œë“œ ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸"""
        print("\nğŸ” ë¹Œë“œ ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸...")
        
        required_files = [
            "python/python.exe",
            "src/oracle_to_bq_cli.py",
            "oracle-to-bq.bat",
            "verify_standalone.bat",
            "config.json",
            "schema.csv"
        ]
        
        all_passed = True
        for file_path in required_files:
            full_path = self.windows_dir / file_path
            if full_path.exists():
                self.log_test(f"íŒŒì¼ ì¡´ì¬: {file_path}", True)
            else:
                self.log_test(f"íŒŒì¼ ì¡´ì¬: {file_path}", False, f"íŒŒì¼ ì—†ìŒ: {full_path}")
                all_passed = False
        
        return all_passed
    
    def test_python_runtime(self) -> bool:
        """Python ëŸ°íƒ€ì„ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ Python ëŸ°íƒ€ì„ í…ŒìŠ¤íŠ¸...")
        
        python_exe = self.windows_dir / "python" / "python.exe"
        
        try:
            # Python ë²„ì „ í™•ì¸
            result = subprocess.run([str(python_exe), "--version"], 
                                  capture_output=True, encoding='utf-8', timeout=10, errors='ignore')
            if result.returncode == 0:
                version = result.stdout.strip()
                self.log_test("Python ë²„ì „ í™•ì¸", True, version)
                return True
            else:
                self.log_test("Python ë²„ì „ í™•ì¸", False, result.stderr)
                return False
        except Exception as e:
            self.log_test("Python ëŸ°íƒ€ì„ ì‹¤í–‰", False, str(e))
            return False
    
    def test_cli_basic_functions(self) -> bool:
        """CLI ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("\nâš™ï¸ CLI ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸...")
        
        oracle_to_bq = self.windows_dir / "oracle-to-bq.bat"
        
        tests = [
            ("--version", "ë²„ì „ ì •ë³´"),
            ("--help", "ë„ì›€ë§"),
        ]
        
        all_passed = True
        for args, description in tests:
            try:
                result = subprocess.run([str(oracle_to_bq), args],
                                      capture_output=True, encoding='utf-8', errors='ignore',
                                      timeout=30, cwd=str(self.windows_dir))
                if result.returncode == 0:
                    self.log_test(f"CLI {description}", True)
                else:
                    self.log_test(f"CLI {description}", False, result.stderr)
                    all_passed = False
            except Exception as e:
                self.log_test(f"CLI {description}", False, str(e))
                all_passed = False
        
        return all_passed
    
    def create_test_csv(self) -> Path:
        """í…ŒìŠ¤íŠ¸ìš© CSV íŒŒì¼ ìƒì„± (ê¸°ë³¸í‚¤ í¬í•¨)"""
        test_data = [
            {
                'TABLE_NAME': 'TEST_TABLE',
                'OWNER': 'TEST_SCHEMA',
                'COLUMN_NAME': 'ID',
                'DATA_TYPE': 'NUMBER',
                'DATA_PRECISION': '10',
                'DATA_SCALE': '0',
                'NULLABLE': 'N',
                'IS_PRIMARY_KEY': 'Y',
                'COLUMN_COMMENT': 'í…ŒìŠ¤íŠ¸ ID'
            },
            {
                'TABLE_NAME': 'TEST_TABLE',
                'OWNER': 'TEST_SCHEMA',
                'COLUMN_NAME': 'NAME',
                'DATA_TYPE': 'VARCHAR2',
                'DATA_PRECISION': '',
                'DATA_SCALE': '',
                'DATA_LENGTH': '100',
                'NULLABLE': 'Y',
                'IS_PRIMARY_KEY': 'N',
                'COLUMN_COMMENT': 'í…ŒìŠ¤íŠ¸ ì´ë¦„'
            },
            {
                'TABLE_NAME': 'TEST_TABLE',
                'OWNER': 'TEST_SCHEMA',
                'COLUMN_NAME': 'AMOUNT',
                'DATA_TYPE': 'NUMBER',
                'DATA_PRECISION': '15',
                'DATA_SCALE': '2',
                'NULLABLE': 'Y',
                'IS_PRIMARY_KEY': 'N',
                'COLUMN_COMMENT': 'í…ŒìŠ¤íŠ¸ ê¸ˆì•¡'
            },
            {
                'TABLE_NAME': 'í•œê¸€í…Œì´ë¸”',
                'OWNER': 'TEST_SCHEMA',
                'COLUMN_NAME': 'í•œê¸€ì»¬ëŸ¼',
                'DATA_TYPE': 'VARCHAR2',
                'DATA_PRECISION': '',
                'DATA_SCALE': '',
                'DATA_LENGTH': '50',
                'NULLABLE': 'N',
                'IS_PRIMARY_KEY': 'Y',
                'COLUMN_COMMENT': 'í•œê¸€ í…ŒìŠ¤íŠ¸'
            }
        ]
        
        test_csv = self.windows_dir / "test_input.csv"
        with open(test_csv, 'w', newline='', encoding='utf-8') as f:
            fieldnames = ['TABLE_NAME', 'OWNER', 'COLUMN_NAME', 'DATA_TYPE', 
                         'DATA_PRECISION', 'DATA_SCALE', 'DATA_LENGTH', 'NULLABLE', 'IS_PRIMARY_KEY', 'COLUMN_COMMENT']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(test_data)
        
        return test_csv
    
    def test_ddl_conversion(self) -> bool:
        """DDL ë³€í™˜ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ”„ DDL ë³€í™˜ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸...")
        
        # í…ŒìŠ¤íŠ¸ CSV ìƒì„±
        test_csv = self.create_test_csv()
        output_dir = self.windows_dir / "test_ddl_output"
        
        # ê¸°ì¡´ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì œê±°
        if output_dir.exists():
            shutil.rmtree(output_dir)
        
        oracle_to_bq = self.windows_dir / "oracle-to-bq.bat"
        
        try:
            # DDL ë³€í™˜ ì‹¤í–‰
            result = subprocess.run([
                str(oracle_to_bq), "convert", str(test_csv),
                "--output-dir", str(output_dir),
                "--project-id", "test-project"
            ], capture_output=True, encoding='utf-8', errors='ignore', timeout=60, cwd=str(self.windows_dir))
            
            if result.returncode == 0:
                self.log_test("DDL ë³€í™˜ ì‹¤í–‰", True)
                
                # ìƒì„±ëœ íŒŒì¼ í™•ì¸
                expected_files = [
                    "test_schema_test_table.sql",
                    "test_schema_í•œê¸€í…Œì´ë¸”.sql"
                ]
                
                files_ok = True
                for expected_file in expected_files:
                    file_path = output_dir / expected_file
                    if file_path.exists():
                        self.log_test(f"DDL íŒŒì¼ ìƒì„±: {expected_file}", True)
                        
                        # íŒŒì¼ ë‚´ìš© ê²€ì¦ (ê¸°ë³¸í‚¤ ì œì•½ì¡°ê±´ í¬í•¨)
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            if ('CREATE' in content and 'test-project.TEST_SCHEMA' in content and 
                                'PRIMARY KEY' in content):
                                self.log_test(f"DDL ë‚´ìš© ê²€ì¦: {expected_file}", True)
                            else:
                                self.log_test(f"DDL ë‚´ìš© ê²€ì¦: {expected_file}", False, "ì˜¬ë°”ë¥¸ DDL í˜•ì‹ì´ ì•„ë‹˜")
                                files_ok = False
                    else:
                        self.log_test(f"DDL íŒŒì¼ ìƒì„±: {expected_file}", False, "íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
                        files_ok = False
                
                return files_ok
            else:
                self.log_test("DDL ë³€í™˜ ì‹¤í–‰", False, result.stderr)
                return False
                
        except Exception as e:
            self.log_test("DDL ë³€í™˜ í…ŒìŠ¤íŠ¸", False, str(e))
            return False
        finally:
            # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬
            if test_csv.exists():
                test_csv.unlink()
            if output_dir.exists():
                shutil.rmtree(output_dir)
    
    def test_korean_support(self) -> bool:
        """í•œê¸€ ì§€ì› í…ŒìŠ¤íŠ¸"""
        print("\nğŸ‡°ğŸ‡· í•œê¸€ ì§€ì› í…ŒìŠ¤íŠ¸...")
        
        # í•œê¸€ í…Œì´ë¸”ëª…/ì»¬ëŸ¼ëª…ì´ í¬í•¨ëœ DDL ë³€í™˜ í…ŒìŠ¤íŠ¸ëŠ” test_ddl_conversionì—ì„œ ìˆ˜í–‰ë¨
        # ì—¬ê¸°ì„œëŠ” ì¶”ê°€ì ì¸ í•œê¸€ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
        
        test_csv = self.create_test_csv()
        output_dir = self.windows_dir / "korean_test_output"
        
        if output_dir.exists():
            shutil.rmtree(output_dir)
        
        oracle_to_bq = self.windows_dir / "oracle-to-bq.bat"
        
        try:
            result = subprocess.run([
                str(oracle_to_bq), "convert", str(test_csv),
                "--output-dir", str(output_dir),
                "--project-id", "í•œê¸€í”„ë¡œì íŠ¸"
            ], capture_output=True, encoding='utf-8', errors='ignore', timeout=60, cwd=str(self.windows_dir))
            
            if result.returncode == 0:
                # í•œê¸€ í…Œì´ë¸” DDL íŒŒì¼ í™•ì¸ - ì‹¤ì œ ìƒì„±ë˜ëŠ” íŒŒì¼ëª… ì‚¬ìš©
                korean_table_file = output_dir / "TEST_SCHEMA_í•œê¸€í…Œì´ë¸”.sql"
                if korean_table_file.exists():
                    with open(korean_table_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        # í•œê¸€ í…Œì´ë¸”ëª…ê³¼ ì»¬ëŸ¼ëª…ì´ ë°±í‹±ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                        if '.í•œê¸€í…Œì´ë¸”`' in content and '`í•œê¸€ì»¬ëŸ¼`' in content:
                            self.log_test("í•œê¸€ í…Œì´ë¸”ëª…/ì»¬ëŸ¼ëª… ë°±í‹± ì²˜ë¦¬", True)
                            return True
                        else:
                            self.log_test("í•œê¸€ í…Œì´ë¸”ëª…/ì»¬ëŸ¼ëª… ë°±í‹± ì²˜ë¦¬", False, f"ë°±í‹± ì²˜ë¦¬ë˜ì§€ ì•ŠìŒ. ë‚´ìš©: {content[:200]}")
                            return False
                else:
                    # ìƒì„±ëœ íŒŒì¼ ëª©ë¡ í™•ì¸
                    files = list(output_dir.glob("*.sql"))
                    self.log_test("í•œê¸€ í…Œì´ë¸” DDL ìƒì„±", False, f"í•œê¸€ í…Œì´ë¸” íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ. ìƒì„±ëœ íŒŒì¼: {[f.name for f in files]}")
                    return False
            else:
                self.log_test("í•œê¸€ í”„ë¡œì íŠ¸ ID ì²˜ë¦¬", False, result.stderr)
                return False
                
        except Exception as e:
            self.log_test("í•œê¸€ ì§€ì› í…ŒìŠ¤íŠ¸", False, str(e))
            return False
        finally:
            if test_csv.exists():
                test_csv.unlink()
            if output_dir.exists():
                shutil.rmtree(output_dir)
    
    def test_encoding_support(self) -> bool:
        """ì¸ì½”ë”© ì§€ì› í…ŒìŠ¤íŠ¸ (UTF-8, EUC-KR)"""
        print("\nğŸ”¤ ì¸ì½”ë”© ì§€ì› í…ŒìŠ¤íŠ¸...")
        
        # EUC-KR í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
        euckr_data = [
            ['TABLE_NAME','OWNER','COLUMN_NAME','DATA_TYPE','DATA_PRECISION','DATA_SCALE','DATA_LENGTH','NULLABLE','IS_PRIMARY_KEY','COLUMN_COMMENT'],
            ['ENCODING_TEST','EUC_SCHEMA','ID','NUMBER','10','0','','N','Y','ì¸ì½”ë”© í…ŒìŠ¤íŠ¸ ID'],
            ['ENCODING_TEST','EUC_SCHEMA','NAME','VARCHAR2','','','50','Y','N','í•œê¸€ ì´ë¦„']
        ]
        
        euckr_csv = self.windows_dir / "test_euckr.csv"
        with open(euckr_csv, 'w', newline='', encoding='euc-kr') as f:
            writer = csv.writer(f)
            writer.writerows(euckr_data)
        
        output_dir = self.windows_dir / "encoding_test_output"
        if output_dir.exists():
            shutil.rmtree(output_dir)
        
        oracle_to_bq = self.windows_dir / "oracle-to-bq.bat"
        
        try:
            result = subprocess.run([
                str(oracle_to_bq), "convert", str(euckr_csv),
                "--output-dir", str(output_dir),
                "--project-id", "encoding-test"
            ], capture_output=True, encoding='utf-8', errors='ignore', timeout=60, cwd=str(self.windows_dir))
            
            if result.returncode == 0:
                # EUC-KR ì¸ì½”ë”© ê°ì§€ í™•ì¸
                stdout_text = result.stdout or ""
                stderr_text = result.stderr or ""
                combined_output = stdout_text + stderr_text
                # ìƒì„±ëœ íŒŒì¼ í™•ì¸ (ì¸ì½”ë”© ê°ì§€ ë©”ì‹œì§€ í™•ì¸ì€ ì„ íƒì‚¬í•­)
                ddl_file = output_dir / "euc_schema_encoding_test.sql"
                if ddl_file.exists():
                    with open(ddl_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        if 'PRIMARY KEY (ID) NOT ENFORCED' in content and 'ì¸ì½”ë”© í…ŒìŠ¤íŠ¸ ID' in content:
                            # ì¸ì½”ë”© ê°ì§€ ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ ë” ì¢‹ì§€ë§Œ, íŒŒì¼ì´ ì •ìƒ ìƒì„±ë˜ë©´ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
                            if "euc-kr" in combined_output.lower() or "cp949" in combined_output.lower():
                                self.log_test("EUC-KR ì¸ì½”ë”© ê°ì§€ ë° íŒŒì¼ ì²˜ë¦¬", True)
                            else:
                                self.log_test("EUC-KR íŒŒì¼ ì²˜ë¦¬", True, "íŒŒì¼ ìƒì„± ì„±ê³µ (ì¸ì½”ë”© ë©”ì‹œì§€ ë¯¸í™•ì¸)")
                            return True
                        else:
                            self.log_test("EUC-KR íŒŒì¼ ì²˜ë¦¬", False, "DDL ë‚´ìš© ì˜¤ë¥˜")
                            return False
                else:
                    self.log_test("EUC-KR íŒŒì¼ ì²˜ë¦¬", False, "DDL íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
                    return False
            else:
                self.log_test("EUC-KR íŒŒì¼ ë³€í™˜", False, result.stderr)
                return False
                
        except Exception as e:
            self.log_test("ì¸ì½”ë”© ì§€ì› í…ŒìŠ¤íŠ¸", False, str(e))
            return False
        finally:
            if euckr_csv.exists():
                euckr_csv.unlink()
            if output_dir.exists():
                shutil.rmtree(output_dir)
    
    def test_merged_output(self) -> bool:
        """ë³‘í•© ì¶œë ¥ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“„ ë³‘í•© ì¶œë ¥ í…ŒìŠ¤íŠ¸...")
        
        test_csv = self.create_test_csv()
        output_dir = self.windows_dir / "merged_test_output"
        
        if output_dir.exists():
            shutil.rmtree(output_dir)
        
        oracle_to_bq = self.windows_dir / "oracle-to-bq.bat"
        
        try:
            result = subprocess.run([
                str(oracle_to_bq), "convert", str(test_csv),
                "--output-dir", str(output_dir),
                "--project-id", "merged-test",
                "--merge-output"
            ], capture_output=True, encoding='utf-8', errors='ignore', timeout=60, cwd=str(self.windows_dir))
            
            if result.returncode == 0:
                # ë³‘í•© íŒŒì¼ í™•ì¸
                merged_file = output_dir / "merged_ddl.sql"
                if merged_file.exists():
                    with open(merged_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                    # ë³‘í•© íŒŒì¼ ë‚´ìš© ê²€ì¦
                    checks = [
                        ('-- Oracle to BigQuery DDL Migration', "í—¤ë”"),
                        ('-- Total tables:', "í…Œì´ë¸” ìˆ˜"),
                        ('CREATE', "DDL êµ¬ë¬¸"),
                        ('PRIMARY KEY', "ê¸°ë³¸í‚¤ ì œì•½ì¡°ê±´"),
                        ('TEST_TABLE', "í…ŒìŠ¤íŠ¸ í…Œì´ë¸”"),
                        ('í•œê¸€í…Œì´ë¸”', "í•œê¸€ í…Œì´ë¸”")
                    ]
                    
                    all_checks_passed = True
                    for check_text, description in checks:
                        if check_text in content:
                            self.log_test(f"ë³‘í•© íŒŒì¼ {description} í™•ì¸", True)
                        else:
                            self.log_test(f"ë³‘í•© íŒŒì¼ {description} í™•ì¸", False, f"'{check_text}' ëˆ„ë½")
                            all_checks_passed = False
                    
                    return all_checks_passed
                else:
                    self.log_test("ë³‘í•© íŒŒì¼ ìƒì„±", False, "merged_ddl.sql íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
                    return False
            else:
                self.log_test("ë³‘í•© ì¶œë ¥ ì‹¤í–‰", False, result.stderr)
                return False
                
        except Exception as e:
            self.log_test("ë³‘í•© ì¶œë ¥ í…ŒìŠ¤íŠ¸", False, str(e))
            return False
        finally:
            if test_csv.exists():
                test_csv.unlink()
            if output_dir.exists():
                shutil.rmtree(output_dir)
    
    def test_basic_performance(self) -> bool:
        """ê¸°ë³¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (í†µí•© í…ŒìŠ¤íŠ¸ìš©)"""
        print("\nâš¡ ê¸°ë³¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸...")
        
        # ì¤‘ê°„ í¬ê¸° í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (500ê°œ ì»¬ëŸ¼)
        test_data = []
        for i in range(500):
            test_data.append({
                'TABLE_NAME': f'PERF_TABLE_{i // 25}',  # 20ê°œ í…Œì´ë¸”
                'OWNER': 'BASIC_PERF',
                'COLUMN_NAME': f'COLUMN_{i}',
                'DATA_TYPE': 'VARCHAR2' if i % 2 == 0 else 'NUMBER',
                'DATA_PRECISION': '10' if i % 2 == 1 else '',
                'DATA_SCALE': '2' if i % 2 == 1 else '',
                'DATA_LENGTH': '100' if i % 2 == 0 else '',
                'NULLABLE': 'Y',
                'COLUMN_COMMENT': f'ê¸°ë³¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì»¬ëŸ¼ {i}'
            })
        
        test_csv = self.windows_dir / "basic_perf_test.csv"
        with open(test_csv, 'w', newline='', encoding='utf-8') as f:
            fieldnames = ['TABLE_NAME', 'OWNER', 'COLUMN_NAME', 'DATA_TYPE', 
                         'DATA_PRECISION', 'DATA_SCALE', 'DATA_LENGTH', 'NULLABLE', 'COLUMN_COMMENT']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(test_data)
        
        output_dir = self.windows_dir / "basic_perf_output"
        if output_dir.exists():
            shutil.rmtree(output_dir)
        
        oracle_to_bq = self.windows_dir / "oracle-to-bq.bat"
        
        try:
            start_time = time.time()
            
            result = subprocess.run([
                str(oracle_to_bq), "convert", str(test_csv),
                "--output-dir", str(output_dir),
                "--project-id", "basic-perf-test"
            ], capture_output=True, encoding='utf-8', errors='ignore', timeout=60, cwd=str(self.windows_dir))
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            if result.returncode == 0:
                generated_files = list(output_dir.glob("*.sql"))
                expected_tables = 20  # 500 ì»¬ëŸ¼ / 25 ì»¬ëŸ¼ë‹¹ 1í…Œì´ë¸” = 20í…Œì´ë¸”
                
                if len(generated_files) == expected_tables:
                    self.log_test("ê¸°ë³¸ ì„±ëŠ¥ ì²˜ë¦¬", True, 
                                f"{len(generated_files)}ê°œ í…Œì´ë¸”, {processing_time:.2f}ì´ˆ")
                    
                    # ê¸°ë³¸ ì„±ëŠ¥ ê¸°ì¤€: 500ê°œ ì»¬ëŸ¼ì„ 30ì´ˆ ì´ë‚´ì— ì²˜ë¦¬
                    if processing_time <= 30:
                        self.log_test("ê¸°ë³¸ ì„±ëŠ¥ ê¸°ì¤€", True, f"{processing_time:.2f}ì´ˆ (ê¸°ì¤€: 30ì´ˆ)")
                        return True
                    else:
                        self.log_test("ê¸°ë³¸ ì„±ëŠ¥ ê¸°ì¤€", False, f"{processing_time:.2f}ì´ˆ (ê¸°ì¤€: 30ì´ˆ)")
                        return False
                else:
                    self.log_test("ê¸°ë³¸ ì„±ëŠ¥ ì²˜ë¦¬", False, 
                                f"ì˜ˆìƒ {expected_tables}ê°œ, ì‹¤ì œ {len(generated_files)}ê°œ")
                    return False
            else:
                self.log_test("ê¸°ë³¸ ì„±ëŠ¥ ì²˜ë¦¬", False, result.stderr)
                return False
                
        except Exception as e:
            self.log_test("ê¸°ë³¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸", False, str(e))
            return False
        finally:
            if test_csv.exists():
                test_csv.unlink()
            if output_dir.exists():
                shutil.rmtree(output_dir)
    
    def run_integration_tests(self) -> bool:
        """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ§ª Windows í¬í„°ë¸” ë²„ì „ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 60)
        
        if not self.windows_dir.exists():
            print("âŒ Windows í¬í„°ë¸” ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print("   ë¨¼ì € build_windows_portable.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë¹Œë“œí•˜ì„¸ìš”.")
            return False
        
        tests = [
            ("ë¹Œë“œ ë¬´ê²°ì„±", self.test_build_integrity),
            ("Python ëŸ°íƒ€ì„", self.test_python_runtime),
            ("CLI ê¸°ë³¸ ê¸°ëŠ¥", self.test_cli_basic_functions),
            ("DDL ë³€í™˜", self.test_ddl_conversion),
            ("í•œê¸€ ì§€ì›", self.test_korean_support),
            ("ì¸ì½”ë”© ì§€ì›", self.test_encoding_support),
            ("ë³‘í•© ì¶œë ¥", self.test_merged_output),
            ("ê¸°ë³¸ ì„±ëŠ¥", self.test_basic_performance),
        ]
        
        passed_tests = 0
        total_tests = len(tests)
        
        for test_name, test_func in tests:
            try:
                if test_func():
                    passed_tests += 1
            except Exception as e:
                self.log_test(f"{test_name} ì‹¤í–‰", False, f"ì˜ˆì™¸ ë°œìƒ: {e}")
        
        return self._generate_test_report("í†µí•© í…ŒìŠ¤íŠ¸", passed_tests, total_tests)
    
    def run_all_tests(self) -> bool:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë‹¨ìœ„ + í†µí•© + ì„±ëŠ¥)"""
        print("ğŸ§ª Windows í¬í„°ë¸” ë²„ì „ ì „ì²´ ìë™í™” í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 70)
        
        # 1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        print("\nğŸ“‹ 1ë‹¨ê³„: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        print("-" * 40)
        unit_test_suite = unittest.TestLoader().loadTestsFromTestCase(DDLGeneratorUnitTests)
        unit_test_runner = unittest.TextTestRunner(verbosity=2, stream=sys.stdout)
        unit_result = unit_test_runner.run(unit_test_suite)
        
        unit_success = unit_result.wasSuccessful()
        unit_passed = unit_result.testsRun - len(unit_result.failures) - len(unit_result.errors)
        
        self.log_test("ë‹¨ìœ„ í…ŒìŠ¤íŠ¸", unit_success, 
                     f"{unit_passed}/{unit_result.testsRun} í†µê³¼")
        
        # 2. í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        print("\nğŸ“‹ 2ë‹¨ê³„: í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        print("-" * 40)
        integration_success = self.run_integration_tests()
        
        # 3. ì „ì²´ ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 70)
        print("ğŸ ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("=" * 70)
        
        total_success = unit_success and integration_success
        
        print(f"ë‹¨ìœ„ í…ŒìŠ¤íŠ¸: {'âœ… í†µê³¼' if unit_success else 'âŒ ì‹¤íŒ¨'} ({unit_passed}/{unit_result.testsRun})")
        print(f"í†µí•© í…ŒìŠ¤íŠ¸: {'âœ… í†µê³¼' if integration_success else 'âŒ ì‹¤íŒ¨'}")
        
        # ìƒì„¸ ê²°ê³¼
        print("\nğŸ“‹ ìƒì„¸ ê²°ê³¼:")
        for result in self.test_results:
            status = "âœ…" if result["success"] else "âŒ"
            message = f" - {result['message']}" if result["message"] else ""
            print(f"{status} {result['test']}{message}")
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        results_file = self.root_dir / "test_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump({
                "summary": {
                    "unit_tests": {
                        "total": unit_result.testsRun,
                        "passed": unit_passed,
                        "failed": len(unit_result.failures) + len(unit_result.errors),
                        "success": unit_success
                    },
                    "integration_tests": {
                        "success": integration_success
                    },
                    "overall_success": total_success
                },
                "details": self.test_results
            }, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ ìƒì„¸ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {results_file}")
        
        if total_success:
            print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì„±ê³µ! Windows í¬í„°ë¸” ë²„ì „ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
            return True
        else:
            print("\nâš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¬¸ì œë¥¼ í™•ì¸í•˜ê³  ìˆ˜ì •í•˜ì„¸ìš”.")
            return False
    
    def _generate_test_report(self, test_type: str, passed: int, total: int) -> bool:
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        success_rate = (passed / total) * 100 if total > 0 else 0
        
        print(f"\nğŸ“Š {test_type} ê²°ê³¼:")
        print(f"ì „ì²´: {total}ê°œ, í†µê³¼: {passed}ê°œ, ì‹¤íŒ¨: {total - passed}ê°œ")
        print(f"ì„±ê³µë¥ : {success_rate:.1f}%")
        
        return success_rate >= 80


class PerformanceTestSuite:
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì „ìš© í´ë˜ìŠ¤"""
    
    def __init__(self, windows_dir: Path):
        self.windows_dir = windows_dir
        self.test_results = []
    
    def log_test(self, test_name: str, success: bool, message: str = ""):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¡œê¹…"""
        status = "âœ… PASS" if success else "âŒ FAIL"
        result = {
            "test": test_name,
            "success": success,
            "message": message
        }
        self.test_results.append(result)
        print(f"{status} {test_name}: {message}")
    
    def test_large_dataset_processing(self) -> bool:
        """ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("\nâš¡ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸...")
        
        # 5000ê°œ ì»¬ëŸ¼, 100ê°œ í…Œì´ë¸” ìƒì„±
        large_test_data = []
        for i in range(5000):
            table_idx = i // 50  # 50ê°œ ì»¬ëŸ¼ë‹¹ 1ê°œ í…Œì´ë¸”
            large_test_data.append({
                'TABLE_NAME': f'PERF_TABLE_{table_idx:03d}',
                'OWNER': 'PERFORMANCE_SCHEMA',
                'COLUMN_NAME': f'COL_{i:04d}',
                'DATA_TYPE': 'VARCHAR2' if i % 3 == 0 else ('NUMBER' if i % 3 == 1 else 'DATE'),
                'DATA_PRECISION': '15' if i % 3 == 1 else '',
                'DATA_SCALE': '2' if i % 3 == 1 else '',
                'DATA_LENGTH': '200' if i % 3 == 0 else '',
                'NULLABLE': 'Y' if i % 2 == 0 else 'N',
                'COLUMN_COMMENT': f'ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì»¬ëŸ¼ {i} - í•œê¸€ í¬í•¨'
            })
        
        large_test_csv = self.windows_dir / "large_perf_test.csv"
        with open(large_test_csv, 'w', newline='', encoding='utf-8') as f:
            fieldnames = ['TABLE_NAME', 'OWNER', 'COLUMN_NAME', 'DATA_TYPE', 
                         'DATA_PRECISION', 'DATA_SCALE', 'DATA_LENGTH', 'NULLABLE', 'COLUMN_COMMENT']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(large_test_data)
        
        output_dir = self.windows_dir / "large_perf_output"
        if output_dir.exists():
            shutil.rmtree(output_dir)
        
        oracle_to_bq = self.windows_dir / "oracle-to-bq.bat"
        
        try:
            start_time = time.time()
            
            result = subprocess.run([
                str(oracle_to_bq), "convert", str(large_test_csv),
                "--output-dir", str(output_dir),
                "--project-id", "performance-test"
            ], capture_output=True, encoding='utf-8', errors='ignore', timeout=180, cwd=str(self.windows_dir))
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            if result.returncode == 0:
                generated_files = list(output_dir.glob("*.sql"))
                expected_tables = 100  # 5000 ì»¬ëŸ¼ / 50 ì»¬ëŸ¼ë‹¹ 1í…Œì´ë¸” = 100í…Œì´ë¸”
                
                if len(generated_files) == expected_tables:
                    throughput = 5000 / processing_time  # ì»¬ëŸ¼/ì´ˆ
                    self.log_test("ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì •í™•ì„±", True, 
                                f"{len(generated_files)}ê°œ í…Œì´ë¸”, {processing_time:.2f}ì´ˆ")
                    
                    # ì„±ëŠ¥ ê¸°ì¤€: 5000ê°œ ì»¬ëŸ¼ì„ 120ì´ˆ ì´ë‚´, 40ì»¬ëŸ¼/ì´ˆ ì´ìƒ
                    if processing_time <= 120 and throughput >= 40:
                        self.log_test("ì„±ëŠ¥ ê¸°ì¤€ ì¶©ì¡±", True, 
                                    f"{throughput:.1f} ì»¬ëŸ¼/ì´ˆ (ê¸°ì¤€: 40ì»¬ëŸ¼/ì´ˆ)")
                        return True
                    else:
                        self.log_test("ì„±ëŠ¥ ê¸°ì¤€ ì¶©ì¡±", False, 
                                    f"{throughput:.1f} ì»¬ëŸ¼/ì´ˆ, {processing_time:.2f}ì´ˆ")
                        return False
                else:
                    self.log_test("ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì •í™•ì„±", False, 
                                f"ì˜ˆìƒ {expected_tables}ê°œ, ì‹¤ì œ {len(generated_files)}ê°œ")
                    return False
            else:
                self.log_test("ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì‹¤í–‰", False, result.stderr)
                return False
                
        except subprocess.TimeoutExpired:
            self.log_test("ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼", False, "180ì´ˆ ì‹œê°„ ì´ˆê³¼")
            return False
        except Exception as e:
            self.log_test("ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì˜ˆì™¸", False, str(e))
            return False
        finally:
            if large_test_csv.exists():
                large_test_csv.unlink()
            if output_dir.exists():
                shutil.rmtree(output_dir)
    
    def test_memory_usage(self) -> bool:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸...")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
        # Windowsì—ì„œ psutil ì—†ì´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ì€ ì œí•œì ì´ë¯€ë¡œ
        # í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì„±ê³µ ì—¬ë¶€ë¡œ íŒë‹¨
        
        test_csv = self.windows_dir / "memory_test.csv"
        test_data = []
        
        # ì¤‘ê°„ í¬ê¸° ë°ì´í„°ì…‹ (1000ê°œ ì»¬ëŸ¼)
        for i in range(1000):
            test_data.append({
                'TABLE_NAME': f'MEM_TABLE_{i // 20}',
                'OWNER': 'MEMORY_TEST',
                'COLUMN_NAME': f'COLUMN_{i}',
                'DATA_TYPE': 'VARCHAR2',
                'DATA_LENGTH': '4000',  # í° VARCHAR2
                'NULLABLE': 'Y',
                'COLUMN_COMMENT': f'ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ìš© ê¸´ ì„¤ëª… ' * 10  # ê¸´ ì„¤ëª…
            })
        
        with open(test_csv, 'w', newline='', encoding='utf-8') as f:
            fieldnames = ['TABLE_NAME', 'OWNER', 'COLUMN_NAME', 'DATA_TYPE', 
                         'DATA_LENGTH', 'NULLABLE', 'COLUMN_COMMENT']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(test_data)
        
        output_dir = self.windows_dir / "memory_test_output"
        if output_dir.exists():
            shutil.rmtree(output_dir)
        
        oracle_to_bq = self.windows_dir / "oracle-to-bq.bat"
        
        try:
            result = subprocess.run([
                str(oracle_to_bq), "convert", str(test_csv),
                "--output-dir", str(output_dir),
                "--project-id", "memory-test"
            ], capture_output=True, encoding='utf-8', errors='ignore', timeout=60, cwd=str(self.windows_dir))
            
            if result.returncode == 0:
                self.log_test("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸", True, "ì •ìƒ ì™„ë£Œ")
                return True
            else:
                self.log_test("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸", False, "ì‹¤í–‰ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            self.log_test("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸", False, str(e))
            return False
        finally:
            if test_csv.exists():
                test_csv.unlink()
            if output_dir.exists():
                shutil.rmtree(output_dir)
    
    def run_performance_tests(self) -> bool:
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("\nâš¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("-" * 40)
        
        tests = [
            ("ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì²˜ë¦¬", self.test_large_dataset_processing),
            ("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", self.test_memory_usage),
        ]
        
        passed_tests = 0
        total_tests = len(tests)
        
        for test_name, test_func in tests:
            try:
                if test_func():
                    passed_tests += 1
            except Exception as e:
                self.log_test(f"{test_name} ì‹¤í–‰", False, f"ì˜ˆì™¸ ë°œìƒ: {e}")
        
        success_rate = (passed_tests / total_tests) * 100
        print(f"\nì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼: {passed_tests}/{total_tests} í†µê³¼ ({success_rate:.1f}%)")
        
        return success_rate >= 80


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Windows í¬í„°ë¸” DDL ìƒì„±ê¸° í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸')
    parser.add_argument('--unit-only', action='store_true', help='ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰')
    parser.add_argument('--integration-only', action='store_true', help='í†µí•© í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰')
    parser.add_argument('--performance-only', action='store_true', help='ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰')
    
    args = parser.parse_args()
    
    test_suite = WindowsPortableTestSuite()
    success = True
    
    if args.unit_only:
        print("ğŸ§ª ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰")
        unit_test_suite = unittest.TestLoader().loadTestsFromTestCase(DDLGeneratorUnitTests)
        unit_test_runner = unittest.TextTestRunner(verbosity=2)
        unit_result = unit_test_runner.run(unit_test_suite)
        success = unit_result.wasSuccessful()
    elif args.integration_only:
        print("ğŸ§ª í†µí•© í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰")
        success = test_suite.run_integration_tests()
    elif args.performance_only:
        print("ğŸ§ª ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰")
        perf_suite = PerformanceTestSuite(test_suite.windows_dir)
        success = perf_suite.run_performance_tests()
    else:
        # ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        success = test_suite.run_all_tests()
    
    sys.exit(0 if success else 1)


    def test_merge_output(self) -> bool:
        """ë³‘í•© ì¶œë ¥ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“„ ë³‘í•© ì¶œë ¥ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸...")
        
        # í…ŒìŠ¤íŠ¸ CSV ìƒì„±
        test_csv = self.create_test_csv()
        output_dir = self.windows_dir / "merge_test_output"
        
        # ê¸°ì¡´ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì œê±°
        if output_dir.exists():
            shutil.rmtree(output_dir)
        
        oracle_to_bq = self.windows_dir / "oracle-to-bq.bat"
        
        try:
            # ë³‘í•© ì¶œë ¥ìœ¼ë¡œ DDL ë³€í™˜ ì‹¤í–‰
            result = subprocess.run([
                str(oracle_to_bq), "convert", str(test_csv),
                "--output-dir", str(output_dir),
                "--project-id", "merge-test",
                "--merge-output"
            ], capture_output=True, encoding='utf-8', errors='ignore', timeout=60, cwd=str(self.windows_dir))
            
            if result.returncode == 0:
                # ë³‘í•© íŒŒì¼ í™•ì¸
                merged_file = output_dir / "merged_ddl.sql"
                if merged_file.exists():
                    with open(merged_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                    # ë³‘í•© íŒŒì¼ ë‚´ìš© ê²€ì¦
                    if ('-- Oracle to BigQuery DDL Migration' in content and
                        'CREATE TABLE' in content and
                        'PRIMARY KEY' in content and
                        'merge-test.TEST_SCHEMA' in content):
                        self.log_test("ë³‘í•© ì¶œë ¥ ê¸°ëŠ¥", True, "ë³‘í•© DDL íŒŒì¼ ìƒì„± ë° ë‚´ìš© ê²€ì¦ ì™„ë£Œ")
                        return True
                    else:
                        self.log_test("ë³‘í•© ì¶œë ¥ ê¸°ëŠ¥", False, "ë³‘í•© íŒŒì¼ ë‚´ìš©ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ")
                        return False
                else:
                    self.log_test("ë³‘í•© ì¶œë ¥ ê¸°ëŠ¥", False, "ë³‘í•© íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
                    return False
            else:
                self.log_test("ë³‘í•© ì¶œë ¥ ì‹¤í–‰", False, result.stderr)
                return False
                
        except Exception as e:
            self.log_test("ë³‘í•© ì¶œë ¥ í…ŒìŠ¤íŠ¸", False, str(e))
            return False
        finally:
            # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬
            if test_csv.exists():
                test_csv.unlink()
            if output_dir.exists():
                shutil.rmtree(output_dir)


if __name__ == "__main__":
    main()